# LING-380-Final-Project-Spring-2020

## Paper introduction

C-command, or constituent command, is a linguistic feature which refers to the relationship between two tokens. First introduced by Tanya Reinhart (1976), c-command is defined as follows: “a node A c-commands a node B iff the first branching node α that dominates A either dominates B, or is immediately dominated by a node α′ which dominates B, where α and α′ are of the same category type” (Reinhart 1983). We can express this relationship through syntax trees. In syntax trees, node A dominates node B if node A is above node B and we can trace a downward path from A to B. Therefore, an alternative definition for c-command through syntax trees is that A c-commands B if a parent of A dominates B. So, in Tree 1 below, “John” c-commands “his.” (Refer to paper for diagrams.) Interestingly, c-command can be found in the grammar of all human languages, suggesting that it may be a feature of the Universal Grammar. The function of c-command in all human languages appears to be to determine agreement between two tokens. An English language example of this can be demonstrated by the coreference between pronouns and proper nouns. In this case, if the pronoun c-commands the proper noun, then it is clear that the sentence refers to two individuals. For example, consider Tree 2. In the sentence generated by Tree 2, “he” c-commands “John.” Therefore, it is clear that “he” and “John” are two distinct individuals. However, in the sentence generated by Tree 1, the reference becomes ambiguous. Here, “John” c-commands
“his”, making it unclear whether “his” refers to John or a second individual. Similar examples of c-command determining the agreement between two tokens exist in other parts of speech, such as subject-verb agreement.
We attempt to implement neural language models to study whether certain architectures can learn the hierarchical c-command structure from natural language. We will compare how different architectures perform at this task. After training our models on a large corpus of natural language, we will test their performance on specific sentences containing c-command.
Through the implementation of several network architectures, we seek to find a model capable of effectively learning c-command. By doing so, we hope to provide more insight into the underlying structure of c-command and expand our understanding of the role of c-command in the Universal Grammar and human linguistic cognition.

For the rest of the paper, see the attached PDF.

## Training the models

To train the models, uncomment the desired model from run_experiment.sh, and then if submitting a job to a Slurm cluster, (like the one maintained by the Yale HPC Center,) use submit_experiment.sh. The file example_lm.py contains the code for loading the SNLI data, defining the model, and training it.

## Testing the models

To test the trained models on BLiMP data, run blimp_final.py and specify the model type you would like to test. Make sure to comment or uncomment the necessary code in blimp_final.py to allow the model to test, given that testing SPINN requires different functions from testing the normal language models. All trained models can be found in the model_checkpoints directory, and their training information (loss, epochs, etc.) can be found in the training_outputs directory.

## Parsing the text

In the blimp_transitions directory, there are some .json files of BLiMP data that has already been entered through a shift-reduce parser. For testing the models, we use these files. If you would like to recreate this parse, setup the Stanford Parser (instructions in setup.txt) then run tree_gen.py, which will parse each sentence in the BLiMP data, binarize the parse tree, and convert it to a shift-reduce parse. You may change the 'principle_A_domain_2' in tools.get_blimp_data('principle_A_domain_2') on line 34 to the name of any other valid BLiMP data file (found here https://github.com/alexwarstadt/blimp/tree/master/data).
